@summary
technology architect fadi chehadé helped set up the infrastructure that makes the internet work -- essential things like the domain name system and ip address standards. today he's focused on finding ways for society to benefit from technology. in a crisp conversation with bryn freedman, curator of the ted institute, chehadé discusses the ongoing war between the west and china over artificial intelligence, how tech companies can become stewards of the power they have to shape lives and economies and what everyday citizens can do to claim power on the internet.
@article
Bryn Freedman: So you said that in the 20th century, global power was in the hands of government. At the beginning of this digital century, it really moved to corporations and that in the future, it would move to individuals. And I've interviewed a lot of people, and they say you're wrong, and they are betting on the companies. So why are you right, and why are individuals going to win out?Fadi Chehadé: Because companies cater to individuals, and we as the citizenry need to start understanding that we have a big role in shaping how the world will be governed, moving forward. Yes, indeed, the tug of war right now is between governments, who lost much of their power to companies because the internet is not built around the nation state system around which governments have power. The internet is transnational. It's not international, and it's not national, and therefore the companies became very powerful. They shape our economy. They shape our society. Governments don't know what to do. Right now, they're reacting. And I fear that if we do not, as the citizenry — which are, in my opinion, the most important leg of that stool — don't take our role, then you are right. The detractors, or the people telling you that businesses will prevail, are right. It will happen.BF: So are you saying that individuals will force businesses or business will be forced to be responsive, or is there a fear that they won't be?FC: I think they will be. Look at two weeks ago, a small company called Skip winning over Uber and Lyft and everyone to actually get the license for the San Francisco scooter business. And if you read why did Skip win, because Skip listened to the people of San Francisco, who were tired of scooters being thrown everywhere, and actually went to the city and said, "We will deploy the service, but we will respond to the people's requirements that we organize ourselves around a set of rules." They self governed their behavior, and they won the contract over some very powerful companies.BF: So speaking of guidelines and self governance, you've spent an entire lifetime creating guidelines and norms for the internet. Do you think those days are over? Who is going to guide, who is going to control, and who is going to create those norms?FC: The rules that govern the technology layers of the internet are now well put in place, and I was very busy for a few years setting those rules around the part of the internet that makes the internet one network. The domain name system, the IP numbers, all of that is in place. However, as we get now into the upper layers of the internet, the issues that affect me and you every day — privacy, security, etc. — the system to create norms for those unfortunately is not in place. So we do have an issue. We have a system of cooperation and governance that really needs to be created right now so that companies, governments and the citizenry can agree how this new digital world is going to advance.BF: So what gives a digital company any incentive? Let's say — Facebook comes to mind — they would say they have their users' best interests at heart, but I think a lot of people would disagree with that.FC: It's been very difficult to watch how tech companies have reacted to the citizenry's response to their technologies. And some of them, two or three years ago, basically dismissed it. The word that I heard in many board rooms is, "We're just a technology platform. It's not my issue if my technology platform causes families to go kill their girls in Pakistan. It's not my issue. It's their problem. I just have a technology platform." Now, I think we are now entering a stage where companies are starting to realize this is no longer sustainable, and they're starting to see the pushback that's coming from people, users, citizens, but also governments that are starting to say, "This cannot be."So I think there is a maturity that is starting to set, especially in that Silicon Valley area, where people are beginning to say, "We have a role." So when I speak to these leaders, I say, "Look, you could be the CEO, a very successful CEO of a company, but you could also be a steward." And that's the key word. "You could be a steward of the power you have to shape the lives and the economies of billions of people. Which one do you want to be?" And the answer is, it's not one or the other. This is what we are missing right now. So when an adult like Brad Smith, the president of Microsoft, said a few months ago, "We need a new set of Geneva Conventions to manage the security of the digital space," many of the senior leaders in Silicon Valley actually spoke against his words. "What do you mean, Geneva Convention? We don't need any Geneva Conventions. We self regulate." But that mood is changing, and I'm starting to see many leaders say, "Help us out." But here lies the conundrum. Who is going to help those leaders do the right thing?BF: So who is going to help them? Because I'd love to interview you for an hour, but give me your biggest fear and your best hope for how this is going to work out.FC: My biggest hope is that we will become each stewards of this new digital world. That's my biggest hope, because I do think, often, we want to put the blame on others. "Oh, it's these CEOs. They're behaving this way." "These governments are not doing enough." But how about us? How is each of us actually taking the responsibility to be a steward of the digital space we live in? And one of the things I've been pushing on university presidents is we need every engineering and science and computer science student who is about to write the next line of code or design the next IoT device to actually have in them a sense of responsibility and stewardship towards what they're building. So I suggested we create a new oath, like the Hippocratic Oath, so that every student entering an engineering program takes a technocratic oath or a wisdom oath or some oath of commitment to the rest of us. That's my best hope, that we all rise. Because governments and businesses will fight over this power game, but where are we? And unless we play into that power table, I think we'll end up in a bad place.My biggest fear? My biggest fear, to be very tactical today, what is keeping me up at night is the current war between the West, the liberal world, and China, in the area of artificial intelligence. There is a real war going on, and for those of us who have lived through the nuclear nonproliferation age and saw how people agreed to take some very dangerous things off the table, well, the Carnegie Endowment just finished a study. They talked to every country that made nuclear weapons and asked them, "Which digital 'weapon' would you take off the table against somebody else's schools or hospitals?" And the answer — from every nuclear power — to this question was, nothing. That's what I'm worried about ... The weaponization of the digital space, and the race to get there.BF: Well, it sounds like you've got a lot of work to do, and so do the rest of us. Fadi, thank you so much. I really appreciate it.FC: Thank you.(Applause)